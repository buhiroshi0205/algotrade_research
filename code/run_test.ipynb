{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import pandas as pd\n",
    "import quantstats as qs\n",
    "from stable_baselines3 import A2C, DQN, PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dailyenv import DailyTradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tickers = 5\n",
    "experiment_name = 'small_policy'\n",
    "\n",
    "tickers = [\"AMM\", \"CIMB\", \"DIGI\", \"GAM\", \"GENM\", \"GENT\", \"HLBK\", \"IOI\", \"KLK\", \"MAY\", \"MISC\", \"NESZ\", \"PBK\", \"PEP\", \"PETD\", \"PTG\", \"RHBBANK\", \"ROTH\", \"T\", \"TNB\"]\n",
    "\n",
    "if n_tickers == 1:\n",
    "    tickers = ['NESZ']\n",
    "else:\n",
    "    tickers = tickers[:n_tickers]\n",
    "\n",
    "if os.path.exists(f'tensorboard_log/{experiment_name}_train'):\n",
    "    i = 1\n",
    "    while os.path.exists(f'tensorboard_log/{experiment_name}({i})_train'):\n",
    "        i += 1\n",
    "    experiment_name += f'({i})'\n",
    "\n",
    "train_env = Monitor(DailyTradingEnv(tickers, dt.datetime(2010, 1, 1), dt.datetime(2018, 1, 1), experiment_name+'_train'))\n",
    "eval_env = Monitor(DailyTradingEnv(tickers, dt.datetime(2018, 1, 1), dt.datetime(2020, 1, 1), experiment_name+'_eval'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test threshold baselines\n",
    "\n",
    "baseline_train_env = DailyTradingEnv(tickers, dt.datetime(2010, 1, 1), dt.datetime(2018, 1, 1))\n",
    "baseline_val_env = DailyTradingEnv(tickers, dt.datetime(2018, 1, 1), dt.datetime(2020, 1, 1))\n",
    "\n",
    "baseline_train_env.pretrain = True\n",
    "for threshold in tqdm(range(11)):\n",
    "    obs = baseline_train_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.zeros(len(tickers)+1)\n",
    "        for i in range(len(tickers)):\n",
    "            if obs[i] * 10 >= threshold:\n",
    "                action[i+1] = 1\n",
    "        if np.sum(action) == 0:\n",
    "            action[0] = 1\n",
    "\n",
    "        obs, reward, done, _ = baseline_train_env.step(action)\n",
    "\n",
    "for threshold in tqdm(range(11)):\n",
    "    obs = baseline_val_env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.zeros(len(tickers)+1)\n",
    "        for i in range(len(tickers)):\n",
    "            if obs[i] * 10 >= threshold:\n",
    "                action[i+1] = 1\n",
    "        if np.sum(action) == 0:\n",
    "            action[0] = 1\n",
    "\n",
    "        obs, reward, done, _ = baseline_val_env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3,figsize=(15,10))\n",
    "baseline_train_env.plot_change('rewards', axs[0][0])\n",
    "baseline_train_env.plot_change(qs.stats.cagr, axs[0][1])\n",
    "baseline_train_env.plot_change(qs.stats.sharpe, axs[0][2])\n",
    "baseline_val_env.plot_change('rewards', axs[1][0])\n",
    "baseline_val_env.plot_change(qs.stats.cagr, axs[1][1])\n",
    "baseline_val_env.plot_change(qs.stats.sharpe, axs[1][2])\n",
    "axs[0][0].set_ylabel('Train', fontsize=18)\n",
    "axs[1][0].set_ylabel('Eval', fontsize=18)\n",
    "axs[0][0].set_title('reward', fontsize=16)\n",
    "axs[0][1].set_title('CAGR', fontsize=16)\n",
    "axs[0][2].set_title('Sharpe', fontsize=16)\n",
    "axs[1][0].set_xlabel('threshold', fontsize=16)\n",
    "axs[1][1].set_xlabel('threshold', fontsize=16)\n",
    "axs[1][2].set_xlabel('threshold', fontsize=16)\n",
    "fig.suptitle('Attention', fontsize=20)\n",
    "# fig.savefig('linear_gru.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBarCallback(BaseCallback):\n",
    "    def __init__(self, total_steps):\n",
    "        self.total_steps = total_steps\n",
    "        super().__init__()\n",
    "    def _on_training_start(self):\n",
    "        self.pbar = tqdm(total=self.total_steps)\n",
    "    def _on_step(self):\n",
    "        self.pbar.update()\n",
    "        if train_env.tf_logger is not None:\n",
    "            train_env.tf_logger.inc_step()\n",
    "        if eval_env.tf_logger is not None:\n",
    "            eval_env.tf_logger.inc_step()\n",
    "    def _on_training_end(self):\n",
    "        self.pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 1000000\n",
    "cb1 = ProgressBarCallback(ts)\n",
    "cb2 = EvalCallback(eval_env, n_eval_episodes=1, eval_freq=ts//100)\n",
    "acb = CallbackList([cb1,cb2])\n",
    "\n",
    "model = A2C('MlpPolicy', train_env, device='cpu', gamma=0, n_steps=5, policy_kwargs={'net_arch': [dict(pi=[5], vf=[5])]})\n",
    "#model = PPO('MlpPolicy', train_env, device='cpu', gamma=0)\n",
    "model.learn(total_timesteps=ts, callback=acb, log_interval=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards, cagr, and sharpe\n",
    "fig, axs = plt.subplots(2,3,figsize=(15,10))\n",
    "baseline_train_env.plot_change('rewards', axs[0][0])\n",
    "baseline_train_env.plot_change(qs.stats.cagr, axs[0][1])\n",
    "baseline_train_env.plot_change(qs.stats.sharpe, axs[0][2])\n",
    "baseline_val_env.plot_change('rewards', axs[1][0])\n",
    "baseline_val_env.plot_change(qs.stats.cagr, axs[1][1])\n",
    "baseline_val_env.plot_change(qs.stats.sharpe, axs[1][2])\n",
    "axs[0][0].set_ylabel('Train')\n",
    "axs[1][0].set_ylabel('Eval')\n",
    "axs[0][0].set_title('reward')\n",
    "axs[0][1].set_title('CAGR')\n",
    "axs[0][2].set_title('Sharpe')\n",
    "axs[1][0].set_xlabel('threshold')\n",
    "axs[1][1].set_xlabel('threshold')\n",
    "axs[1][2].set_xlabel('threshold')\n",
    "fig.suptitle('RL-baseline comparison on 20-stock portfolio', fontsize=16)\n",
    "\n",
    "axs[0][0].axhline(np.mean(train_env.get_series('rewards',-1)), color='orange')\n",
    "axs[0][1].axhline(qs.stats.cagr(train_env.get_series('bankroll',-1)), color='orange')\n",
    "axs[0][2].axhline(qs.stats.sharpe(train_env.get_series('bankroll',-1)), color='orange')\n",
    "axs[1][0].axhline(np.mean(eval_env.get_series('rewards',-1)), color='orange')\n",
    "axs[1][1].axhline(qs.stats.cagr(eval_env.get_series('bankroll',-1)), color='orange')\n",
    "axs[1][2].axhline(qs.stats.sharpe(eval_env.get_series('bankroll',-1)), color='orange')\n",
    "\n",
    "fig.savefig(f'graphs/{experiment_name}.png')\n",
    "# train_env.save_logs(f'saves/{experiment_name}.npz')\n",
    "# model.save(f'saves/{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sanity check x 1000, verify all stats and graphs that it's working\n",
    "2. can it fit all 20 stocks in portfolio (higher dimensionality might make some parameters bad etc)\n",
    "3. next steps (E.g. limits, costs)\n",
    "- we're trading based on good predictions from train set, but when we give bad predictions for val set then it screws up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- Singlestock overfitting very hard, can fit to best baseline but absolutely bombs the validation run\n",
    "- 5 stocks actually performing negatively on val set\n",
    "- 20 tickers run significantly slower than 1 ticker, maybe we can change datastructure from pandas to numpy\n",
    "- what do the dividends mean?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "942cb71450adb9db1b0c51df6c94acfcd5033dc0e1cf0ec4b4d409cd1f14d03b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
