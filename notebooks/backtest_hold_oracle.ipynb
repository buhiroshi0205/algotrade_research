{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88772bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "daily_prices = pd.read_csv('../data/dfs/daily/price.csv', index_col=0)\n",
    "daily_prices['Dates'] = pd.to_datetime(daily_prices['Dates'])\n",
    "daily_prices = daily_prices.set_index('Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891b1928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2000, 2002, 2002, 2003]), array([2003, 2005, 2005, 2006]), array([2006, 2008, 2008, 2009]), array([2009, 2011, 2011, 2012]), array([2012, 2014, 2014, 2015]), array([2015, 2017, 2017, 2018]), array([2018, 2020, 2020, 2021])]\n"
     ]
    }
   ],
   "source": [
    "train_val_splits = []\n",
    "block = np.array([2000,2002,2002,2003])\n",
    "for i in range(7):\n",
    "    train_val_splits.append(block+[3*i,3*i,3*i,3*i])\n",
    "    \n",
    "print(train_val_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4749cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {}\n",
    "for i in daily_prices.columns:\n",
    "    tmpdf = pd.read_csv('../data/Day Data with Volatility/{} MK Equity.csv'.format(i))\n",
    "    tmpdf.Dates = pd.to_datetime(tmpdf.Dates)\n",
    "    tmpdf = tmpdf.set_index('Dates')\n",
    "    state_dict[i]=tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75759e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, prices_df, timeframe, starting_balance=1000000, pfstate=False):\n",
    "        super(DayEnv, self).__init__()\n",
    "        self.prices = prices_df[f'{timeframe[0]}-1-1':f'{timeframe[1]}-1-1']\n",
    "        self.dates = self.prices.index\n",
    "        self.num_timesteps = len(self.dates)\n",
    "        self.symbols = self.prices.columns\n",
    "        self.action_space = gym.spaces.MultiDiscrete(tuple([3]*len(self.symbols)))\n",
    "        self.portfolio_in_state = pfstate\n",
    "        if self.portfolio_in_state:\n",
    "            self.observation_space = gym.spaces.Box(-1,1, shape=(2, len(self.symbols)))\n",
    "        else:\n",
    "            self.observation_space = gym.spaces.Box(-1,1, shape=(len(self.symbols),))\n",
    "        self.starting_balance = starting_balance\n",
    "        self.curr_portfolio = np.zeros(len(self.symbols))\n",
    "        self.transaction_cost = 0.025\n",
    "        \n",
    "        self.total_transaction_costs = [0.0, 0.0]\n",
    "\n",
    "        \n",
    "    def step(self, action: np.ndarray):\n",
    "        assert len(action) == len(self.symbols)\n",
    "        \n",
    "        sell_mask = np.logical_and((action == 0), self.curr_portfolio > 0)\n",
    "        #hold_mask = (action == 1)\n",
    "        buy_mask = (action == 2)\n",
    "        \n",
    "        curr_prices = self.prices.iloc[self.curr_idx].values\n",
    "        next_prices = self.prices.iloc[self.curr_idx + 1].values\n",
    "        \n",
    "        # First sell stocks\n",
    "        realized_profits = np.dot(curr_prices[sell_mask], self.curr_portfolio[sell_mask]) * (1-self.transaction_cost)\n",
    "        self.total_transaction_costs[0] += np.dot(curr_prices[sell_mask], self.curr_portfolio[sell_mask]) * (self.transaction_cost)\n",
    "\n",
    "        # Add realized profit to cash balance\n",
    "        self.cash_balance += realized_profits\n",
    "        self.curr_portfolio[sell_mask] = 0\n",
    "        \n",
    "        # Then buy stocks evenly with remaining balance\n",
    "        weights = np.zeros(action.shape)\n",
    "        weights[buy_mask] = action[buy_mask] / np.sum(action[buy_mask])\n",
    "        \n",
    "        new_shares = np.floor(self.cash_balance * weights / (curr_prices*(1+self.transaction_cost)))\n",
    "        shares_cost = np.dot(curr_prices, new_shares) * (1+self.transaction_cost)\n",
    "        \n",
    "        self.total_transaction_costs[1] += np.dot(curr_prices, new_shares) * self.transaction_cost\n",
    "        \n",
    "        self.curr_portfolio += new_shares\n",
    "        self.cash_balance -= shares_cost\n",
    "        self.curr_balance = self.cash_balance + np.dot(self.curr_portfolio, next_prices)\n",
    "        profits = self.curr_balance - self.last_balance\n",
    "        \n",
    "        reward = self._calc_reward(profits)\n",
    "        self.last_balance = self.curr_balance\n",
    "        \n",
    "        self.history.append(self.curr_balance)\n",
    "        self.curr_idx += 1\n",
    "        \n",
    "        done=False\n",
    "        if self.curr_idx == self.num_timesteps-1 or self.curr_balance <= 0:\n",
    "            done = True\n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        self.cash_balance = self.starting_balance\n",
    "        self.curr_balance = self.starting_balance\n",
    "        self.last_balance = self.curr_balance\n",
    "        self.history = [self.curr_balance]\n",
    "        self.total_transaction_costs = [0.0, 0.0]\n",
    "        self.curr_portfolio = np.zeros(len(self.symbols))\n",
    "        return self._get_obs()\n",
    "\n",
    "    \n",
    "    def _calc_reward(self, profit):\n",
    "        return profit/self.curr_balance\n",
    "\n",
    "    def _get_obs(self):\n",
    "        if self.curr_idx == self.num_timesteps-1 or self.curr_balance <= 0:\n",
    "            oracle=np.zeros(self.observation_space.shape)\n",
    "        else:\n",
    "            oracle = np.clip(np.log(self.prices.values[self.curr_idx+1]/self.prices.values[self.curr_idx]),-1,1)\n",
    "        fractional = self.curr_portfolio * self.prices.iloc[self.curr_idx].values /self.curr_balance\n",
    "        if self.portfolio_in_state:\n",
    "            return np.vstack([oracle, fractional])\n",
    "        else:\n",
    "            return oracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74151bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.0212618 , -0.00509772,  0.02715099, -0.01086731, -0.01801851,\n",
      "       -0.00732604,  0.02509679, -0.01562532, -0.0093844 , -0.00718351,\n",
      "       -0.00739603, -0.00589972, -0.00489797, -0.03922071, -0.00468385,\n",
      "       -0.02932762, -0.03427024, -0.02620237, -0.0339262 , -0.0051414 ]), -0.02591871974174865, False, {})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "654130.1358899999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = DayEnv(daily_prices, train_val_splits[0][:2])\n",
    "test.reset()\n",
    "print(test.step(np.array([0,1,2,0,1,2,0,1,2,0,1,2,0,1,2,0,1,2,0,1])))\n",
    "test.step(np.array([0,0,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0]))\n",
    "test.step(np.array([0,0,1,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0]))\n",
    "\n",
    "654130.1358899999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0985e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C\n",
    "import random\n",
    "import quantstats as qs\n",
    "\n",
    "class AgentTrainer():\n",
    "    \n",
    "    def __init__(self, prices_df, splits, num_episodes, eval_frequency, num_trials, model_params, pfstate = False):\n",
    "        self.splits_df = []\n",
    "        for split in splits:\n",
    "            self.splits_df.append((DayEnv(prices_df, split[:2], pfstate=False), DayEnv(prices_df, split[2:], pfstate=False)))\n",
    "        self.model_type = model_params['type']\n",
    "        # self.lr = model_params['lr']\n",
    "        self.num_episodes = num_episodes\n",
    "        self.eval_frequency = eval_frequency\n",
    "        self.prices_df = prices_df\n",
    "        self.num_trials=num_trials\n",
    "        \n",
    "        \n",
    "    def train(self, split_id=-1):\n",
    "        self.initialize(split_id)\n",
    "        print('Val Start Date:', self.val_env.dates.values[0])\n",
    "        for eps in range(self.num_episodes):\n",
    "            if (eps+1) % self.eval_frequency == 0:\n",
    "                self.validate(eps)\n",
    "            self.model.learn(total_timesteps=self.total_timesteps)\n",
    "        return self.mean_rewards, self.mean_sharpes\n",
    "        \n",
    "    def validate(self, episode):\n",
    "        for trial in range(self.num_trials):\n",
    "            done = False\n",
    "            obs = self.val_env.reset()\n",
    "            sum_r = 0\n",
    "            while not done:\n",
    "                action, _states = self.model.predict(obs, deterministic=True)\n",
    "                if True:\n",
    "                    f = open(\"results_oracle_final_0.025.txt\", \"a\")\n",
    "                    f.write(str(obs) + \"$\" + str(action) + \"\\n\")\n",
    "                    f.close()\n",
    "                obs, rewards, done, info = self.val_env.step(action)\n",
    "                sum_r += rewards\n",
    "            f = open(\"transaction_costs_oracle_0.025.txt\", \"a\")\n",
    "            f.write(str(episode) + \"$\" + str(trial) + \"$\" + str(self.val_env.total_transaction_costs) + \"\\n\")\n",
    "            f.close()\n",
    "            \n",
    "            f = open(\"curr_balance_costs_oracle_0.025.txt\", \"a\")\n",
    "            f.write(str(episode) + \"$\" + str(trial) + \"$\" + str(self.val_env.curr_balance) + \"\\n\")\n",
    "            f.close()\n",
    "            self.mean_rewards[trial,episode//self.eval_frequency] = sum_r\n",
    "            self.mean_sharpes[trial,episode//self.eval_frequency] = qs.stats.sharpe(pd.Series(self.val_env.history))\n",
    "        print(episode, self.mean_rewards[:, episode//self.eval_frequency].mean(),\n",
    "              self.mean_sharpes[:, episode//self.eval_frequency].mean())\n",
    "            \n",
    "    def initialize(self, split_id):\n",
    "        if split_id == -1:\n",
    "            choice_split = random.choice(self.splits_df)\n",
    "        else:\n",
    "            choice_split = self.splits_df[split_id]\n",
    "        self.train_env = choice_split[0]\n",
    "        self.val_env = choice_split[1]\n",
    "        self.total_timesteps = self.train_env.num_timesteps\n",
    "        if self.model_type == 'PPO':\n",
    "            self.model = PPO('MlpPolicy', self.train_env, learning_rate=1e-3, ent_coef=1e-3, gamma=0,\n",
    "                             policy_kwargs={'net_arch': [dict(pi=[100], vf=[100])]}, device='cpu')\n",
    "        elif self.model_type == 'A2C':\n",
    "            self.model = A2C('MlpPolicy', self.train_env, learning_rate=self.lr)\n",
    "        self.mean_rewards = np.zeros((self.num_trials,self.num_episodes//self.eval_frequency))\n",
    "        self.mean_sharpes = np.zeros((self.num_trials,self.num_episodes//self.eval_frequency))\n",
    "    \n",
    "    def backtest(self):\n",
    "        all_results = []\n",
    "        for split_id in range(len(self.splits_df)):\n",
    "            all_results.append(self.train(split_id))\n",
    "        return all_results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bbd723-dfad-4bc1-b2c9-02e23e75e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Start Date: 2020-01-01T00:00:00.000000000\n",
      "9 -0.15501368854392716 -0.4625924541503692\n",
      "19 -0.1229341760256347 -0.4043315315079871\n",
      "29 -0.10514101024225915 -0.4096292725379551\n",
      "39 -0.15290116490651068 -0.5882549261180209\n",
      "49 -0.12077888420149926 -0.4224327535565252\n",
      "59 -0.11629448373536358 -0.4517571755655629\n",
      "69 -0.11868294205200472 -0.47063801670612343\n",
      "79 -0.10502715510049584 -0.3705387809304749\n",
      "89 -0.10448588715416633 -0.3630131134762803\n",
      "99 -0.10388818031241245 -0.3642393745773288\n",
      "109 -0.10714711934817307 -0.3831091510561913\n",
      "119 -0.11483592339556026 -0.48647989232790456\n",
      "129 -0.0720576982521378 -0.18318556546373532\n",
      "139 -0.11348571945834404 -0.3933062078260222\n",
      "149 -0.11997908885008642 -0.3461980547809574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m AgentTrainer(daily_prices, train_val_splits, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m, model_params, pfstate\u001b[38;5;241m=\u001b[39mx)\n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_val_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     11\u001b[0m         ks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mAgentTrainer.train\u001b[0;34m(self, split_id)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (eps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(eps)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_rewards, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_sharpes\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:314\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m: PPOSelf,\n\u001b[1;32m    303\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    312\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PPOSelf:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:251\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    247\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 251\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:170\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 170\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/policies.py:587\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[1;32m    586\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(obs)\n\u001b[0;32m--> 587\u001b[0m latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[1;32m    589\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/torch_layers.py:230\u001b[0m, in \u001b[0;36mMlpExtractor.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m:return: latent_policy, latent_value of the specified network.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    If all layers are shared, then ``latent_policy == latent_value``\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m shared_latent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_net(features)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshared_latent\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(shared_latent)\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/zfsauton2/home/vduvvur/.conda/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_params = {'type':'PPO'}\n",
    "# model_params = {'type':'A2C', 'lr':0.0007}\n",
    "\n",
    "fig,axs = plt.subplots(1,2, figsize=(10,3))\n",
    "\n",
    "for x in [1,0]:\n",
    "    trainer = AgentTrainer(daily_prices, train_val_splits, 200, 10, 5, model_params, pfstate=x)\n",
    "    results = trainer.train(len(train_val_splits)-1)\n",
    "\n",
    "    for i in range(2):\n",
    "        ks = np.arange(20) * 10\n",
    "        avs = np.mean(results[i], axis=0)\n",
    "        maxs = np.max(results[i], axis=0)\n",
    "        mins = np.min(results[i], axis=0)\n",
    "\n",
    "        axs[i].fill_between(ks, mins, maxs, alpha=0.1)\n",
    "        if x:\n",
    "            axs[i].plot(ks, avs, '-o', markersize=1, label='portfolio in state')\n",
    "            print(\"Portfolio\", \"returns\" if i == 0 else \"sharpe\", avs[-1])\n",
    "        else:\n",
    "            axs[i].plot(ks, avs, '-o', markersize=1, label='no portfolio')\n",
    "            print(\"No Portfolio\", \"returns\" if i == 0 else \"sharpe\", avs[-1])\n",
    "        axs[i].legend()\n",
    "        axs[i].set_xlabel('Episode', fontsize=12)\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel('Return', fontsize=12)\n",
    "        else:\n",
    "            axs[i].set_ylabel('Sharpe', fontsize=12)\n",
    "plt.suptitle(model_params['type'], fontsize=16)\n",
    "\n",
    "plt.savefig(\"./plots/hold_state/{}_curve_oracle.png\".format(model_params['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81b7c665-0e2b-48a5-9531-1419f6e200f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20)\n",
      "[2.87270328 4.3209423  5.7836333  6.75525003 7.36123049 7.74084808\n",
      " 7.93297357 7.54159418 6.77080133 4.65954061 4.59100397 4.21396659\n",
      " 3.66446371 3.30881031 5.33129529 6.83524749 7.64866766 7.92801999\n",
      " 6.93899676 6.58757829]\n",
      "[4.46702750e-01 3.89557674e-03 1.26679578e-04 4.66200780e-01\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.65249129e-01 1.35938148e-04 6.60856325e-04\n",
      " 1.13671253e-03 9.68624990e-03 8.19693471e-03 1.55093512e-03\n",
      " 4.67883671e-01 0.00000000e+00 0.00000000e+00 4.54005149e-01]\n"
     ]
    }
   ],
   "source": [
    "print(results[0].shape)\n",
    "print(np.mean(results[0],axis=0))\n",
    "print(np.std(results[0],axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ab118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
